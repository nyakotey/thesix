% =============================================================================
% SAMPLE BIBLIOGRAPHY FILE (BibTeX format)
% 
% This file contains sample references in BibTeX format following
% Harvard referencing style as required by the thesis guidelines.
% 
% Replace these sample entries with your actual references.
% Use a reference manager like Zotero, Mendeley, or EndNote to generate
% BibTeX entries automatically.
% =============================================================================

% Book with single author
@book{Adarkwa2011,
    author = {Adarkwa, K. K.},
    title = {Future of the Tree: Towards Growth and Development of Kumasi},
    publisher = {University Printing Press (UPK)},
    address = {KNUST, Kumasi},
    year = {2011}
}

% Book with two authors
@book{Duah2015,
    author = {Duah, D. Y. and Amos-Abanye, S.},
    title = {The Urban Poor and the Excesses of Rents: Evidence from Kumasi, Ghana},
    publisher = {University Printing Press (UPK)},
    address = {Kumasi},
    year = {2015}
}

% Book with three or more authors
@book{PokuBoansi2015,
    author = {Poku-Boansi, M. and Duah, D. Y. and Amos-Abanye, S.},
    title = {The Urban Poor and the Excesses of Rents: Evidence from Kumasi, Ghana},
    publisher = {University Printing Press (UPK)},
    address = {Kumasi},
    year = {2015}
}

% Journal article (online)
@article{Cobbinah2015a,
    author = {Cobbinah, P. B. and Erdiaw-Kwasie, M. O. and Amoateng, P.},
    title = {Rethinking sustainable development within the framework of poverty and urbanisation in developing countries},
    journal = {Environmental Development},
    volume = {13},
    pages = {18--32},
    year = {2015},
    url = {http://dx.doi.org/10.1016/j.envdev.2014.11.001}
}

% Journal article (online) - same authors, different year letter
@article{Cobbinah2015b,
    author = {Cobbinah, P. B. and Erdiaw-Kwasie, M. O. and Amoateng, P.},
    title = {Africa's urbanisation: implications for sustainable development},
    journal = {Cities},
    volume = {47},
    pages = {62--72},
    year = {2015},
    url = {http://dx.doi.org/10.1016/j.cities.2015.03.013},
    note = {[Accessed 30/07/2015]}
}

% Journal article (printed)
@article{PokuBoansi2013,
    author = {Poku-Boansi, M. and Adarkwa, K. K.},
    title = {The determinants of demand for public transport services in Kumasi, Ghana},
    journal = {Journal of Science and Technology},
    volume = {33},
    number = {3},
    pages = {1--15},
    year = {2013}
}

% Conference paper
@inproceedings{Adarkwa2011conf,
    author = {Adarkwa, K. K. and Poku-Boansi, M.},
    title = {Climate Change, Food Security, and Poverty in Ghana's Northern Regions - Policy Implications for Local Governments},
    booktitle = {Senior Policy Seminar Towards a Green Economy: The Effects of Climate Change on Food Security and Earth Resources in Africa and Asia},
    address = {Vietnam},
    month = {September 21-24},
    year = {2011}
}

% Chapter in book
@incollection{Quagraine2011,
    author = {Quagraine, V.},
    title = {Kumasi as a Garden City},
    editor = {Adarkwa, K. K.},
    booktitle = {The future of the tree: Towards growth and development of Kumasi},
    pages = {14--34},
    publisher = {KNUST Printing Press},
    address = {Kumasi, Ghana},
    year = {2011}
}

% Newspaper article
@article{Tamakloe2008,
    author = {Tamakloe, E. K. A.},
    title = {[Article Title Here]},
    journal = {Daily Graphic},
    month = {February 26},
    year = {2008}
}

% Newspaper article (online)
@article{Tamakloe2008online,
    author = {Tamakloe, E. K. A.},
    title = {[Article Title Here]},
    journal = {Daily Graphic},
    pages = {14},
    month = {February 26},
    year = {2008},
    url = {http://www.dailygraphiconline.com/gh},
    note = {[Accessed: 22nd May 2008]}
}

% Map
@misc{TownPlanning2014,
    author = {{Town and Country Planning Department}},
    title = {Infrastructure Map of Kumasi},
    howpublished = {Scale two hundred and fifty kilometres to one feet},
    publisher = {Infrastructure Survey},
    address = {Kumasi},
    year = {2014}
}

@inproceedings{amendolaDroneLandingMoving2023,
  title = {Drone {{Landing}} on {{Moving UGV Platform}} with {{Reinforcement Learning Based Offsets}}},
  booktitle = {2023 {{IEEE International Symposium}} on {{Smart Electronic Systems}} ({{iSES}})},
  author = {Amendola, Jose and Cenkeramaddi, Linga Reddy and Jha, Ajit},
  year = {2023},
  month = dec,
  pages = {16--21},
  issn = {2832-3602},
  doi = {10.1109/iSES58672.2023.00015},
  urldate = {2025-02-14},
  abstract = {Safe and precise landings of unmanned aerial vehicles (also known as drones) in dynamic platforms such as unmanned ground vehicle (U G V) can significantly enhance the practical applicability and efficiency of operations that benefit from complementing aerial and terrestrial vehicles. In this paper, we propose a Reinforcement Learning (RL) based framework for landing a drone on a moving U G V platform. The trained policy provides position offset commands to an underlying PID position control, which, in turn, converts it into forces and torques to maneuver the drone towards the dynamically moving UGV platform. The policy is trained for three different UGV platform velocities (1 m/s, 2 m/s and 3 m/s) with three runs for each case. The training curves converge to maximal accumulated reward and provide policies that enabled successful drone landings. By simplifying the RL problem and incorporating PID control, we achieve efficient training, and robustness in the landing task, overcoming challenges in generalization across dynamics and avoiding the complexity of more sophisticated control systems.},
  keywords = {classification,Convolution neural network,Drones,fault detection,Land vehicles,laser,PD control,PI control,Position control,Reinforcement learning,Robustness,Training,Vehicle dynamics},
  file = {C\:\\Users\\user\\Zotero\\storage\\F47DIX2K\\Amendola et al. - 2023 - Drone Landing on Moving UGV Platform with Reinforcement Learning Based Offsets.pdf;C\:\\Users\\user\\Zotero\\storage\\6WJJC8KQ\\10466794.html}
}

@article{azarDroneDeepReinforcement2021,
  title = {Drone {{Deep Reinforcement Learning}}: {{A Review}}},
  shorttitle = {Drone {{Deep Reinforcement Learning}}},
  author = {Azar, Ahmad Taher and Koubaa, Anis and Ali Mohamed, Nada and Ibrahim, Habiba A. and Ibrahim, Zahra Fathy and Kazim, Muhammad and Ammar, Adel and Benjdira, Bilel and Khamis, Alaa M. and Hameed, Ibrahim A. and Casalino, Gabriella},
  year = {2021},
  month = jan,
  journal = {Electronics},
  volume = {10},
  number = {9},
  pages = {999},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-9292},
  doi = {10.3390/electronics10090999},
  urldate = {2025-04-02},
  abstract = {Unmanned Aerial Vehicles (UAVs) are increasingly being used in many challenging and diversified applications. These applications belong to the civilian and the military fields. To name a few; infrastructure inspection, traffic patrolling, remote sensing, mapping, surveillance, rescuing humans and animals, environment monitoring, and Intelligence, Surveillance, Target Acquisition, and Reconnaissance (ISTAR) operations. However, the use of UAVs in these applications needs a substantial level of autonomy. In other words, UAVs should have the ability to accomplish planned missions in unexpected situations without requiring human intervention. To ensure this level of autonomy, many artificial intelligence algorithms were designed. These algorithms targeted the guidance, navigation, and control (GNC) of UAVs. In this paper, we described the state of the art of one subset of these algorithms: the deep reinforcement learning (DRL) techniques. We made a detailed description of them, and we deduced the current limitations in this area. We noted that most of these DRL methods were designed to ensure stable and smooth UAV navigation by training computer-simulated environments. We realized that further research efforts are needed to address the challenges that restrain their deployment in real-life scenarios.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {control,deep reinforcement learning (DRL),guidance,literature review,machine learning,navigation,UAVs,unmanned aerial vehicles},
  file = {C:\Users\user\Zotero\storage\W6Y6XLNX\Azar et al. - 2021 - Drone Deep Reinforcement Learning A Review.pdf}
}

@article{backmanReinforcementLearningShared2023,
  title = {Reinforcement Learning for Shared Autonomy Drone Landings},
  author = {Backman, Kal and Kuli{\'c}, Dana and Chung, Hoam},
  year = {2023},
  month = dec,
  journal = {Autonomous Robots},
  volume = {47},
  number = {8},
  pages = {1419--1438},
  issn = {1573-7527},
  doi = {10.1007/s10514-023-10143-3},
  urldate = {2025-02-14},
  abstract = {Novice pilots find it difficult to operate and land unmanned aerial vehicles (UAVs), due to the complex UAV dynamics, challenges in depth perception, lack of expertise with the control interface and additional disturbances from the ground effect. Therefore we propose a shared autonomy approach to assist pilots in safely landing a UAV under conditions where depth perception is difficult and safe landing zones are limited. Our approach is comprised of two modules: a perception module that encodes information onto a compressed latent representation using two RGB-D cameras and a policy module that is trained with the reinforcement learning algorithm TD3 to discern the pilot's intent and to provide control inputs that augment the user's input to safely land the UAV. The policy module is trained in simulation using a population of simulated users. Simulated users are sampled from a parametric model with four parameters, which model a pilot's tendency to conform to the assistant, proficiency, aggressiveness and speed. We conduct a user study (\$\$n=28\$\$) where human participants were tasked with landing a physical UAV on one of several platforms under challenging viewing conditions. The assistant, trained with only simulated user data, improved task success rate from 51.4 to 98.2\% despite being unaware of the human participants' goal or the structure of the environment a priori. With the proposed assistant, regardless of prior piloting experience, participants performed with a proficiency greater than the most experienced unassisted participants.},
  langid = {english},
  keywords = {Artificial Intelligence,Latent representations,Reinforcement learning,Shared autonomy,Unmanned aerial vehicles},
  file = {C:\Users\user\Zotero\storage\J3AJXWC8\Backman et al. - 2023 - Reinforcement learning for shared autonomy drone landings.pdf}
}
